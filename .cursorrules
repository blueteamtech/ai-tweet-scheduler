# AI Tweet Scheduler v2.0 - Cursor Rules

## Project Context
**MVP COMPLETE** - Building v2.0 Personality AI Enhancement
- v1.0: Basic AI tweet scheduler with Twitter integration âœ…
- v2.0: Personality-driven content generation with bulk scheduling
- Reference: `v2-personality-ai-plan.md` for development roadmap

## Tech Stack (v2.0)
- Frontend: Next.js 14 with TypeScript
- Database: Supabase + pgvector (vector embeddings)
- AI: OpenAI GPT-4o + text-embedding-3-small
- Scheduling: QStash by Upstash
- Styling: Tailwind CSS
- Deployment: Vercel

---

## ğŸš¨ CRITICAL SAFEGUARDS (Prevent Hours of Troubleshooting)

### ğŸ“š API DOCUMENTATION - ALWAYS CHECK FIRST
**MANDATORY:** Before ANY API integration, search for current documentation
```
1. web_search: "OpenAI embeddings API 2025 documentation"
2. web_search: "Supabase pgvector extension syntax 2025"
3. Verify parameter formats, response structures, rate limits
4. Check for breaking changes in last 6 months
```

### ğŸ—„ï¸ DATABASE ROLLBACK STRATEGY
**PROBLEM:** Git revert doesn't rollback database changes
**SOLUTION:** 
1. **Before ANY database changes:**
   - Create backup SQL in comments: `-- ROLLBACK: DROP TABLE new_table;`
   - Document rollback commands in `database-rollback-commands.md`
   - Test rollback SQL in development first

2. **Database Migration Pattern:**
   ```sql
   -- FORWARD MIGRATION
   CREATE TABLE user_writing_samples (...);
   
   -- ROLLBACK (test these first!):
   -- DROP TABLE IF EXISTS user_writing_samples CASCADE;
   ```

3. **Always create rollback before forward migration**

### ğŸš€ VERCEL DEPLOYMENT STATE TRACKING
**PROBLEM:** Environment variables and database can get out of sync
**SOLUTION:**
1. **Before deploying:** Document current state in `deployment-state.md`
2. **Environment Variables:** Keep local `.env.local` and Vercel settings in sync
3. **Database Schema:** Ensure Supabase matches local SQL files
4. **Rollback Plan:** Document how to revert Vercel + Database to previous working state

---

## ğŸ”§ V2.0 SPECIFIC RULES

### OpenAI Embeddings (v2.0)
- **Model:** `text-embedding-3-small` (check current pricing)
- **Dimensions:** 1536 (verify current default)
- **Rate Limits:** Check current limits before bulk operations
- **Cost Management:** Estimate costs for embedding user writing samples

### Supabase pgvector (v2.0)
- **Extension:** Enable pgvector extension first
- **Vector Storage:** `embedding vector(1536)` (verify dimensions)
- **Similarity Search:** Use cosine similarity for semantic matching
- **Performance:** Add indexes for user_id + similarity queries

### Bulk Processing (v2.0)
- **Rate Limiting:** Implement delays between API calls
- **Error Handling:** Graceful failure for bulk operations
- **Progress Tracking:** Show progress for long-running operations
- **Cancellation:** Allow users to cancel bulk operations

---

## ğŸ“‹ V2.0 DEVELOPMENT WORKFLOW

### Before Starting ANY Phase:
1. âœ… Check `v2-personality-ai-plan.md` checklist
2. âœ… Check current API documentation (web_search)
3. âœ… Update `database-schema.md` with planned changes
4. âœ… Create rollback commands for database changes
5. âœ… Test rollback commands before implementing forward changes

### Database Changes:
1. **Plan:** Update `database-schema.md` first
2. **Rollback:** Create and test rollback SQL
3. **Forward:** Implement changes
4. **Verify:** Run verification SQL
5. **Document:** Add to recent changes with date

### API Integration:
1. **Research:** web_search for current documentation
2. **Debug Route:** Create simple test endpoint first
3. **Parameters:** Verify formats match current docs
4. **Error Handling:** Handle rate limits and failures
5. **Testing:** Test edge cases and error scenarios

---

## ğŸ—‚ï¸ FILE ORGANIZATION (v2.0)

```
AI-Personality-Tweets-to-Scheduler/
â”œâ”€â”€ v2-personality-ai-plan.md          # Development roadmap
â”œâ”€â”€ database-schema.md                 # Schema documentation
â”œâ”€â”€ database-rollback-commands.md      # Rollback procedures
â”œâ”€â”€ deployment-state.md                # Vercel/DB state tracking
â””â”€â”€ ai-tweet-scheduler/
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ components/
    â”‚   â”‚   â”œâ”€â”€ WritingSampleInput.tsx  # v2.0: Writing analysis
    â”‚   â”‚   â”œâ”€â”€ BulkTweetInput.tsx      # v2.0: Bulk generation
    â”‚   â”‚   â””â”€â”€ TweetQueue.tsx          # v2.0: Queue management
    â”‚   â”œâ”€â”€ lib/
    â”‚   â”‚   â”œâ”€â”€ embeddings.ts           # v2.0: OpenAI embeddings
    â”‚   â”‚   â”œâ”€â”€ similarity.ts           # v2.0: Vector similarity
    â”‚   â”‚   â””â”€â”€ bulk-scheduler.ts       # v2.0: Smart scheduling
    â”‚   â””â”€â”€ app/api/
    â”‚       â”œâ”€â”€ analyze-writing/        # v2.0: Writing analysis
    â”‚       â”œâ”€â”€ bulk-generate-tweets/   # v2.0: Bulk generation
    â”‚       â””â”€â”€ bulk-schedule-tweets/   # v2.0: Bulk scheduling
```

---

## âš ï¸ COMMON V2.0 PITFALLS TO AVOID

### OpenAI API Issues:
- **Embeddings Model:** Verify `text-embedding-3-small` is still current
- **Rate Limits:** Different limits for chat vs embeddings APIs
- **Batch Processing:** Don't overwhelm API with concurrent requests
- **Error Codes:** Handle 429 (rate limit) and 400 (content policy) properly

### Vector Database Issues:
- **pgvector Extension:** Must be enabled before creating vector columns
- **Dimension Mismatch:** Embedding dimensions must match vector column
- **Index Performance:** Create proper indexes for similarity searches
- **Storage Costs:** Vector storage is expensive, optimize storage

### Bulk Operations Issues:
- **Memory Usage:** Don't load all data into memory at once
- **User Experience:** Show progress for long operations
- **Error Recovery:** Allow retry of failed bulk operations
- **Rate Limiting:** Respect API limits during bulk processing

---

## ğŸ¯ DEVELOPMENT PRIORITIES

1. **Database First:** Set up tables and rollback procedures
2. **API Research:** Verify current documentation for all APIs
3. **Simple Implementation:** Start with basic functionality
4. **Error Handling:** Robust error handling for all operations
5. **User Experience:** Progress indicators and feedback
6. **Performance:** Optimize for bulk operations
7. **Testing:** Test edge cases and failure scenarios

---

## ğŸ›‘ TROUBLESHOOTING WORKFLOW (Prevent Getting Stuck)

### **3-Attempt Rule**: 
If working on the same problem for more than 3 attempts based on user feedback:

1. **STOP** making agentic attempts
2. **SWITCH TO PLAN MODE:**
   - **Analyze**: What exactly is wrong?
   - **Logic**: What are we trying to fix and why?
   - **Impact**: How does this affect the overall v2.0 plan?
   - **Strategy**: Clear step-by-step plan to resolve the issue
3. **Present the analysis** to user for agreement
4. **Continue with 3 more attempts** after plan approval

### **Plan Mode Template:**
```
ğŸ›‘ **SWITCHING TO PLAN MODE** (3+ attempts on same issue)

**Problem Analysis:**
- What's broken: [specific issue]
- Root cause: [why it's happening]
- Current attempts tried: [list what was tried]

**Fix Strategy:**
- Step 1: [specific action]
- Step 2: [specific action]
- Step 3: [specific action]

**Overall Impact:**
- How this affects v2.0 development
- Which phases might be delayed
- Dependencies that are blocked

**Next Steps:**
- Immediate actions needed
- Success criteria to confirm fix
- Backup plan if this approach fails
```

---

## ğŸ“ REFERENCE CHECKLIST

Before any major work:
- [ ] Current API docs checked (web_search)
- [ ] Database rollback plan created
- [ ] `v2-personality-ai-plan.md` phase identified
- [ ] `database-schema.md` updated
- [ ] Deployment state documented
- [ ] Not stuck on same problem for 3+ attempts

Remember: v2.0 introduces complex AI and vector operations. Take time to research and plan to avoid costly mistakes. 