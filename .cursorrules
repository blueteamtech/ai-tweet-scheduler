# AI Tweet Scheduler v2.0 - Cursor Rules

## Project Context
**MVP COMPLETE** - Building v2.0 Personality AI Enhancement
- v1.0: Basic AI tweet scheduler with Twitter integration ✅
- v2.0: Personality-driven content generation with bulk scheduling
- Reference: `v2-personality-ai-plan.md` for development roadmap

## Tech Stack (v2.0)
- Frontend: Next.js 14 with TypeScript
- Database: Supabase + pgvector (vector embeddings) - **MCP Integrated**
- AI: OpenAI GPT-4o + text-embedding-3-small
- Scheduling: QStash by Upstash
- Styling: Tailwind CSS
- Deployment: Vercel

---

## 🚨 CRITICAL SAFEGUARDS (Prevent Hours of Troubleshooting)

### 📚 API INTEGRATION STRATEGY - CHECK EXISTING FIRST
**MANDATORY:** Before ANY API work, check what's already integrated
```
1. EXISTING APIs (Keys Already Set):
   ✅ OpenAI API (OPENAI_API_KEY) - GPT-4o + text-embedding-3-small
   ✅ Supabase (NEXT_PUBLIC_SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY, etc.)
   ✅ QStash (QSTASH_TOKEN) - Scheduling service
   ✅ Twitter API (TWITTER_API_KEY, TWITTER_API_SECRET) - OAuth + posting

2. ONLY for NEW APIs:
   - web_search: "[API NAME] documentation 2025"
   - Verify parameter formats, response structures, rate limits
   - Check for breaking changes in last 6 months
   - Get API keys from user

3. For EXISTING APIs:
   - Assume keys are already configured
   - Check current documentation for updates/changes
   - Verify we're using latest best practices
```

### 🗄️ DATABASE MANAGEMENT WITH MCP SUPABASE
**CONTEXT:** MCP Supabase provides direct database interaction - no manual SQL files needed
**INTEGRATION:** Database schema and operations handled through MCP tools

**WORKFLOW:**
1. **Database Changes:** Use MCP Supabase tools for schema management
2. **Live Database:** Direct interaction through MCP eliminates manual SQL execution
3. **Schema Inspection:** MCP provides real-time database schema information
4. **Data Operations:** Use MCP for queries, inserts, updates, and migrations

**NO LONGER NEEDED:**
- ❌ Manual `database-schema.md` files
- ❌ Manual `database-rollback-commands.md` files  
- ❌ Manual SQL migration files
- ❌ Manual verification scripts
- ❌ Manual deployment state tracking

---

## 🔍 CODE QUALITY & ESLINT PREVENTION
**MANDATORY:** Prevent build failures by following these rules BEFORE committing

### **ESLint Rules to Follow:**
1. **TypeScript Strictness:**
   - ❌ NEVER use `any` type - create proper interfaces instead
   - ✅ Use `const` for variables that are never reassigned (not `let`)
   - ✅ Define proper types for function parameters and returns
   - ✅ Use type guards for runtime type checking

2. **React/JSX Rules:**
   - ❌ NEVER use unescaped quotes in JSX: `"text"` 
   - ✅ Always escape quotes: `&quot;text&quot;` or `&ldquo;text&rdquo;`
   - ✅ Use proper event handler types: `React.MouseEvent`, `React.ChangeEvent`
   - ✅ Include `key` props for mapped elements

3. **Variable Declaration:**
   - ✅ Use `const` for values that never change
   - ✅ Use `let` only when the variable will be reassigned
   - ❌ Avoid `var` completely

### **Pre-Commit Checklist:**
Before ANY git commit, verify:
- [ ] No TypeScript errors (`any` types, missing interfaces)
- [ ] No unescaped entities in JSX (quotes, apostrophes)
- [ ] Proper const/let usage (prefer const when possible)
- [ ] All imports are used and correctly typed
- [ ] Event handlers have proper TypeScript types

### **Common Pitfalls & Fixes:**
```typescript
// ❌ BAD: Using 'any' type
const items = data.map((item: any) => ({ ... }))

// ✅ GOOD: Proper interface
interface DatabaseItem { id: string; name: string; }
const items = data.map((item: DatabaseItem) => ({ ... }))

// ❌ BAD: Using 'let' when never reassigned
let config = { apiKey: '...', timeout: 5000 }

// ✅ GOOD: Using 'const' 
const config = { apiKey: '...', timeout: 5000 }

// ❌ BAD: Unescaped quotes in JSX
<span>Click "Save" to continue</span>

// ✅ GOOD: Escaped quotes
<span>Click &quot;Save&quot; to continue</span>
```

### **Build Validation Process:**
1. **Local Testing:** Run `npm run build` locally before pushing
2. **Type Check:** Ensure all TypeScript types are properly defined
3. **ESLint Clean:** No warnings or errors in ESLint output
4. **Import Check:** All imports are used and paths are correct

---

## 🔧 V2.0 SPECIFIC RULES

### OpenAI Embeddings (v2.0)
- **Model:** `text-embedding-3-small` (check current pricing)
- **Dimensions:** 1536 (verify current default)
- **Rate Limits:** Check current limits before bulk operations
- **Cost Management:** Estimate costs for embedding user writing samples

### Supabase pgvector (v2.0)
- **Extension:** MCP handles pgvector extension management
- **Vector Storage:** `embedding vector(1536)` (verify dimensions)
- **Similarity Search:** Use cosine similarity for semantic matching
- **Performance:** MCP manages indexes for user_id + similarity queries

### Bulk Processing (v2.0)
- **Rate Limiting:** Implement delays between API calls
- **Error Handling:** Graceful failure for bulk operations
- **Progress Tracking:** Show progress for long-running operations
- **Cancellation:** Allow users to cancel bulk operations

---

## 📋 V2.0 DEVELOPMENT WORKFLOW

### Before Starting ANY Phase:
1. ✅ Check `v2-personality-ai-plan.md` checklist
2. ✅ Check current API documentation (web_search)
3. ✅ Use MCP Supabase for database schema inspection
4. ✅ Test database operations through MCP before implementation

### Database Changes:
1. **Inspect Current Schema:** Use MCP Supabase tools to understand current state
2. **Plan Changes:** Define required schema modifications
3. **Implement:** Use MCP for direct database modifications
4. **Verify:** Use MCP to confirm changes applied correctly
5. **Test:** Ensure application works with new schema

### API Integration:
1. **Research:** web_search for current documentation
2. **Debug Route:** Create simple test endpoint first
3. **Parameters:** Verify formats match current docs
4. **Error Handling:** Handle rate limits and failures
5. **Testing:** Test edge cases and error scenarios

---

## 🗂️ FILE ORGANIZATION (v2.0)

```
AI-Personality-Tweets-to-Scheduler/
├── v2-personality-ai-plan.md          # Development roadmap
└── src/
    ├── components/
    │   ├── WritingSampleInput.tsx  # v2.0: Writing analysis
    │   ├── BulkTweetInput.tsx      # v2.0: Bulk generation
    │   └── TweetQueue.tsx          # v2.0: Queue management
    ├── lib/
    │   ├── embeddings.ts           # v2.0: OpenAI embeddings
    │   ├── similarity.ts           # v2.0: Vector similarity
    │   └── bulk-scheduler.ts       # v2.0: Smart scheduling
    └── app/api/
        ├── analyze-writing/        # v2.0: Writing analysis
        ├── bulk-generate-tweets/   # v2.0: Bulk generation
        └── bulk-schedule-tweets/   # v2.0: Bulk scheduling
```

---

## ⚠️ COMMON V2.0 PITFALLS TO AVOID

### OpenAI API Issues:
- **Embeddings Model:** Verify `text-embedding-3-small` is still current
- **Rate Limits:** Different limits for chat vs embeddings APIs
- **Batch Processing:** Don't overwhelm API with concurrent requests
- **Error Codes:** Handle 429 (rate limit) and 400 (content policy) properly

### Vector Database Issues:
- **pgvector Extension:** MCP manages extension automatically
- **Dimension Mismatch:** Embedding dimensions must match vector column
- **Index Performance:** MCP handles proper indexes for similarity searches
- **Storage Costs:** Vector storage is expensive, optimize storage

### Bulk Operations Issues:
- **Memory Usage:** Don't load all data into memory at once
- **User Experience:** Show progress for long operations
- **Error Recovery:** Allow retry of failed bulk operations
- **Rate Limiting:** Respect API limits during bulk processing

---

## 🎯 DEVELOPMENT PRIORITIES

1. **Database Inspection:** Use MCP to understand current schema
2. **API Research:** Verify current documentation for all APIs
3. **Simple Implementation:** Start with basic functionality
4. **Error Handling:** Robust error handling for all operations
5. **User Experience:** Progress indicators and feedback
6. **Performance:** Optimize for bulk operations
7. **Testing:** Test edge cases and failure scenarios

---

## 🛑 TROUBLESHOOTING WORKFLOW (Prevent Getting Stuck)

### **3-Attempt Rule**: 
If working on the same problem for more than 3 attempts based on user feedback:

1. **STOP** making agentic attempts
2. **SWITCH TO PLAN MODE:**
   - **Analyze**: What exactly is wrong?
   - **Logic**: What are we trying to fix and why?
   - **Impact**: How does this affect the overall v2.0 plan?
   - **Strategy**: Clear step-by-step plan to resolve the issue
3. **Present the analysis** to user for agreement
4. **Continue with 3 more attempts** after plan approval

### **Plan Mode Template:**
```
🛑 **SWITCHING TO PLAN MODE** (3+ attempts on same issue)

**Problem Analysis:**
- What's broken: [specific issue]
- Root cause: [why it's happening]
- Current attempts tried: [list what was tried]

**Fix Strategy:**
- Step 1: [specific action]
- Step 2: [specific action]
- Step 3: [specific action]

**Overall Impact:**
- How this affects v2.0 development
- Which phases might be delayed
- Dependencies that are blocked

**Next Steps:**
- Immediate actions needed
- Success criteria to confirm fix
- Backup plan if this approach fails
```

---

## 📝 REFERENCE CHECKLIST

Before any major work:
- [ ] Current API docs checked (web_search)
- [ ] Database schema inspected via MCP Supabase
- [ ] `v2-personality-ai-plan.md` phase identified
- [ ] Not stuck on same problem for 3+ attempts

**Before ANY commit:**
- [ ] Code Quality: No `any` types, proper interfaces defined
- [ ] ESLint Clean: No unescaped JSX entities, proper const/let usage
- [ ] Build Test: `npm run build` passes locally (recommended)
- [ ] Type Safety: All imports typed correctly

**MCP Supabase Integration Benefits:**
- ✅ Real-time database schema inspection
- ✅ Direct database operations without manual SQL
- ✅ Automatic pgvector extension management
- ✅ Simplified database development workflow

Remember: v2.0 introduces complex AI and vector operations. Use MCP Supabase for efficient database management and take time to research APIs to avoid costly mistakes. 